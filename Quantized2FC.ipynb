{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ce7VW4nwpuWE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YUgYCHQtYW5z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.cuda as cuda\n",
        "# Load in relevant libraries, and alias where appropriate\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Parameter\n",
        "from torch.nn.modules.conv import _ConvNd, init\n",
        "from torch.nn.modules.utils import _single, _pair, _triple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "N_EOwyDV-6mw"
      },
      "outputs": [],
      "source": [
        "def zeropoint_quantize(X,W):\n",
        "\n",
        "    tensor_input = torch.tensor(X)\n",
        "    tensor_weight = torch.tensor(W)\n",
        "    #getting Mins of each array\n",
        "    Mins=torch.empty(2)\n",
        "    #print(\"Mins=\",Mins)\n",
        "    Mins[0]=torch.tensor(torch.min(tensor_input))\n",
        "    Mins[1]=torch.tensor(torch.min(tensor_weight))\n",
        "\n",
        "    #print(\"Mins=\",Mins)\n",
        "\n",
        "    #getting Maxs of each array\n",
        "    Maxs=torch.empty(2)\n",
        "    #print(\"Maxs=\",Maxs)\n",
        "    Maxs[0]=torch.tensor(torch.max(tensor_input))\n",
        "    Maxs[1]=torch.tensor(torch.max(tensor_weight))\n",
        "\n",
        "    #print(\"Maxs=\",Maxs)\n",
        "\n",
        "\n",
        "    # Calculate value range (denominator)\n",
        "    x_range = torch.max(Maxs) - torch.min(Mins)\n",
        "    #print(\"x_range=\",x_range)\n",
        "    x_range = 1 if x_range == 0 else x_range\n",
        "\n",
        "    # Calculate scale\n",
        "    scale = 255 / x_range\n",
        "    #print(\"scale=\",scale)\n",
        "\n",
        "\n",
        "    # Shift by zero-point\n",
        "    zeropoint = (-scale * torch.min(Mins)).round()\n",
        "\n",
        "\n",
        "    # Scale and round the inputs\n",
        "    X_quant = torch.clip((X * scale + zeropoint).round(), 0, 255)\n",
        "    W_quant = torch.clip((W * scale + zeropoint).round(), 0, 255)\n",
        "\n",
        "\n",
        "    #print(\"X_quant=\",X_quant)\n",
        "    #print(\"X_quant=\",W_quant)\n",
        "\n",
        "    return X_quant.to(torch.int32),W_quant.to(torch.int32),scale,zeropoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "D1tX_k42Kpbq"
      },
      "outputs": [],
      "source": [
        "def zeropoint_dequantize(X,z,scale,sumation):\n",
        "\n",
        "    # Dequantize\n",
        "    X_dequant = (X - (z*z)-(scale*z*sumation)) / (scale*scale)\n",
        "\n",
        "    #print(\"X_dequant=\",X_dequant)\n",
        "\n",
        "\n",
        "    return  X_dequant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Qm3Zl2fjB-cq"
      },
      "outputs": [],
      "source": [
        "# Define relevant variables for the ML task\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 4\n",
        "\n",
        "# Device will determine whether to run the training on GPU or CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "#Loading the dataset and preprocessing\n",
        "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
        "                                           train = True,\n",
        "                                           transform = transforms.Compose([\n",
        "                                                  transforms.Resize((32,32)),\n",
        "                                                  transforms.ToTensor(),\n",
        "                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
        "                                           download = True)\n",
        "\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
        "                                          train = False,\n",
        "                                          transform = transforms.Compose([\n",
        "                                                  transforms.Resize((32,32)),\n",
        "                                                  transforms.ToTensor(),\n",
        "                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
        "                                          download=True)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "\n",
        "class nnModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(nnModel, self).__init__()\n",
        "\n",
        "        self.conv1 =  nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.relu1=nn.ReLU()\n",
        "        self.maxpool1=nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.relu2=nn.ReLU()\n",
        "        self.maxpool2=nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.conv3 = nn.Conv2d(16, 120, kernel_size=5)\n",
        "\n",
        "        self.fc1 = nn.Linear(120, 84)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.maxpool1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.maxpool2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu4(out)\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mKWP69Wwnzj1"
      },
      "outputs": [],
      "source": [
        "# Load the saved model weights\n",
        "model = nnModel(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BojUUCsAu9sh",
        "outputId": "f40b66c5-062c-4973-a19b-0dad2d0ff9a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'conv3.weight', 'conv3.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"
          ]
        }
      ],
      "source": [
        "print(model.state_dict().keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEOm7r4Tn92t",
        "outputId": "d36049c6-577a-41e7-db8e-44cbe5296b1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/lenet-weight/weightsLenetPytorch3Conv-2.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jW2X4jeXNcHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d82556-5970-47e4-ffd3-fad6d7dfb52b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer_weightsfc1= torch.Size([84, 120])\n",
            "layer_biasfc1= torch.Size([84])\n",
            "layer_weightsfc2= torch.Size([10, 84])\n",
            "layer_biasfc2= torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "layer_weights1 = model.state_dict()['conv1.weight']\n",
        "layer_bias1 = model.state_dict()['conv1.bias']\n",
        "layer_weights2 = model.state_dict()['conv2.weight']\n",
        "layer_bias2 = model.state_dict()['conv2.bias']\n",
        "layer_weights3 = model.state_dict()['conv3.weight']\n",
        "layer_bias3 = model.state_dict()['conv3.bias']\n",
        "layer_weightsfc1 = model.state_dict()['fc1.weight']\n",
        "layer_biasfc1 = model.state_dict()['fc1.bias']\n",
        "layer_weightsfc2 = model.state_dict()['fc2.weight']\n",
        "layer_biasfc2 = model.state_dict()['fc2.bias']\n",
        "#print(\"layer_weights1=\",layer_weights1)\n",
        "#print(\"layer_bias1=\",layer_bias1)\n",
        "#print(\"layer_weights2=\",layer_weights2)\n",
        "#print(\"layer_bias2=\",layer_bias2)\n",
        "#print(\"layer_weights3=\",layer_weights3)\n",
        "#print(\"layer_bias3=\",layer_bias3)\n",
        "print(\"layer_weightsfc1=\",layer_weightsfc1.shape)\n",
        "print(\"layer_biasfc1=\",layer_biasfc1.shape)\n",
        "print(\"layer_weightsfc2=\",layer_weightsfc2.shape)\n",
        "print(\"layer_biasfc2=\",layer_biasfc2.shape)\n",
        "#print(layer_weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_weights1.shape,layer_weights2.shape,layer_weights3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0YWgCmxN_r5",
        "outputId": "07f8217c-0848-4ddd-8333-c2affdf74fa6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([6, 1, 5, 5]),\n",
              " torch.Size([16, 6, 5, 5]),\n",
              " torch.Size([120, 16, 5, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FCLayer1(nn.Linear):\n",
        "    def __init__(self, n_inputs, n_outputs):\n",
        "        super(FCLayer1, self).__init__(n_inputs, n_outputs)\n",
        "        print(\"n_inputsfc1=\",n_inputs)\n",
        "        print(\"n_outputsfc1=\",n_outputs)\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_outputs = n_outputs\n",
        "\n",
        "        # Initialize weights and biases as PyTorch tensors\n",
        "        self.weights = layer_weightsfc1#nn.Parameter(torch.randn(n_outputs, n_inputs))\n",
        "        self.biases =layer_biasfc1# nn.Parameter(torch.zeros(n_outputs))\n",
        "\n",
        "    def forward(self, input_data):\n",
        "\n",
        "        output=torch.zeros((input_data.shape[0],self.n_outputs))\n",
        "        #print(\"shapeoutputfc1=\",output.shape)\n",
        "\n",
        "        for batch in range(input_data.shape[0]):\n",
        "\n",
        "            for y in range(self.n_outputs):\n",
        "                #print(\"input_data\",input_data)\n",
        "                #print(\"input_data[batch,:]\",input_data[batch,:])\n",
        "                #print(\"self.weights\",self.weights)\n",
        "                #print(\"self.weights[y,:]\",self.weights[y,:])\n",
        "\n",
        "                X=input_data[batch,:]\n",
        "                W=self.weights[y,:]\n",
        "                #///////////////////////////Quantize input & Weight//////////////////////////////\n",
        "                summation= torch.flatten(X + W)\n",
        "                Xquantize,Wquantize,scale,zeropoint=zeropoint_quantize(X,W)\n",
        "                #print(\"Xquantize\",Xquantize)\n",
        "                #print(\"Wquantize\",Wquantize)\n",
        "\n",
        "                Outputsc=torch.zeros(len(Xquantize))\n",
        "                Outputsc=Xquantize*Wquantize\n",
        "                #print(\"Outputsc\",Outputsc)\n",
        "                OutDequantize=zeropoint_dequantize(Outputsc,zeropoint,scale,summation)\n",
        "                #print(\"OutDequantize\",OutDequantize)\n",
        "                output[batch,y] = torch.sum(OutDequantize) + self.biases[y]\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "9dRb9aQzfZvv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCLayer2(nn.Linear):\n",
        "    def __init__(self, n_inputs, n_outputs):\n",
        "        super(FCLayer2, self).__init__(n_inputs, n_outputs)\n",
        "        print(\"n_inputsfc2=\",n_inputs)\n",
        "        print(\"n_outputsfc2=\",n_outputs)\n",
        "\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_outputs = n_outputs\n",
        "\n",
        "        # Initialize weights and biases as PyTorch tensors\n",
        "        self.weights = layer_weightsfc2#nn.Parameter(torch.randn(n_outputs, n_inputs))\n",
        "        self.biases = layer_biasfc2#nn.Parameter(torch.zeros(n_outputs))\n",
        "\n",
        "    def forward(self, input_data):\n",
        "\n",
        "        output=torch.zeros((input_data.shape[0],self.n_outputs))\n",
        "        #print(\"shapeoutputfc1=\",output.shape)\n",
        "\n",
        "        for batch in range(input_data.shape[0]):\n",
        "\n",
        "            for y in range(self.n_outputs):\n",
        "                #print(\"input_data\",input_data)\n",
        "                #print(\"input_data[batch,:]\",input_data[batch,:])\n",
        "                #print(\"self.weights\",self.weights)\n",
        "                #print(\"self.weights[y,:]\",self.weights[y,:])\n",
        "\n",
        "                X=input_data[batch,:]\n",
        "                W=self.weights[y,:]\n",
        "                #///////////////////////////Quantize input & Weight//////////////////////////////\n",
        "                summation= torch.flatten(X + W)\n",
        "                Xquantize,Wquantize,scale,zeropoint=zeropoint_quantize(X,W)\n",
        "                #print(\"Xquantize\",Xquantize)\n",
        "                #print(\"Wquantize\",Wquantize)\n",
        "\n",
        "                Outputsc=torch.zeros(len(Xquantize))\n",
        "                Outputsc=Xquantize*Wquantize\n",
        "                #print(\"Outputsc\",Outputsc)\n",
        "                OutDequantize=zeropoint_dequantize(Outputsc,zeropoint,scale,summation)\n",
        "                #print(\"OutDequantize\",OutDequantize)\n",
        "                output[batch,y] = torch.sum(OutDequantize) + self.biases[y]\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "7Luc-1tGfdLQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Szx7DzUSe28y"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        self.conv1 =  nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.relu1=nn.ReLU()\n",
        "        self.maxpool1=nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.relu2=nn.ReLU()\n",
        "        self.maxpool2=nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.conv3 = nn.Conv2d(16, 120, kernel_size=5)\n",
        "\n",
        "        self.fc1 = FCLayer1(120, 84)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc2 = FCLayer2(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.maxpool1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.maxpool2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu4(out)\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NQhLeRYwe4Lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8a80ae-e196-4bd0-8b87-420b45eab058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_inputsfc1= 120\n",
            "n_outputsfc1= 84\n",
            "n_inputsfc2= 84\n",
            "n_outputsfc2= 10\n"
          ]
        }
      ],
      "source": [
        "model1 = MyModel(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApaM4XD0fi9l",
        "outputId": "db325f25-b12c-4fad-af7b-e6b48554abf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "model1.load_state_dict(torch.load('/content/drive/MyDrive/lenet-weight/weightsLenetPytorch3Conv-2.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaVILxwW2iEU",
        "outputId": "80d8c50a-9bfc-4533-ac21-1749b3de498b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-d432a0e2c37e>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tensor_input = torch.tensor(X)\n",
            "<ipython-input-24-d432a0e2c37e>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tensor_weight = torch.tensor(W)\n",
            "<ipython-input-24-d432a0e2c37e>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Mins[0]=torch.tensor(torch.min(tensor_input))\n",
            "<ipython-input-24-d432a0e2c37e>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Mins[1]=torch.tensor(torch.min(tensor_weight))\n",
            "<ipython-input-24-d432a0e2c37e>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Maxs[0]=torch.tensor(torch.max(tensor_input))\n",
            "<ipython-input-24-d432a0e2c37e>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Maxs[1]=torch.tensor(torch.max(tensor_weight))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total= 64\n",
            "total= 128\n",
            "total= 192\n",
            "total= 256\n",
            "total= 320\n",
            "total= 384\n",
            "total= 448\n",
            "total= 512\n",
            "total= 576\n",
            "total= 640\n",
            "total= 704\n",
            "total= 768\n",
            "total= 832\n",
            "total= 896\n",
            "total= 960\n",
            "total= 1024\n",
            "total= 1088\n",
            "total= 1152\n",
            "total= 1216\n",
            "total= 1280\n",
            "total= 1344\n",
            "total= 1408\n",
            "total= 1472\n",
            "total= 1536\n",
            "total= 1600\n",
            "total= 1664\n",
            "total= 1728\n",
            "total= 1792\n",
            "total= 1856\n",
            "total= 1920\n",
            "total= 1984\n",
            "total= 2048\n",
            "total= 2112\n",
            "total= 2176\n",
            "total= 2240\n",
            "total= 2304\n",
            "total= 2368\n",
            "total= 2432\n",
            "total= 2496\n",
            "total= 2560\n",
            "total= 2624\n",
            "total= 2688\n",
            "total= 2752\n",
            "total= 2816\n",
            "total= 2880\n",
            "total= 2944\n",
            "total= 3008\n",
            "total= 3072\n",
            "total= 3136\n",
            "total= 3200\n",
            "total= 3264\n",
            "total= 3328\n",
            "total= 3392\n",
            "total= 3456\n",
            "total= 3520\n",
            "total= 3584\n",
            "total= 3648\n",
            "total= 3712\n",
            "total= 3776\n",
            "total= 3840\n",
            "total= 3904\n",
            "total= 3968\n",
            "total= 4032\n",
            "total= 4096\n",
            "total= 4160\n",
            "total= 4224\n",
            "total= 4288\n",
            "total= 4352\n",
            "total= 4416\n",
            "total= 4480\n",
            "total= 4544\n",
            "total= 4608\n",
            "total= 4672\n",
            "total= 4736\n",
            "total= 4800\n",
            "total= 4864\n",
            "total= 4928\n",
            "total= 4992\n",
            "total= 5056\n",
            "total= 5120\n",
            "total= 5184\n",
            "total= 5248\n",
            "total= 5312\n",
            "total= 5376\n",
            "total= 5440\n",
            "total= 5504\n",
            "total= 5568\n",
            "total= 5632\n",
            "total= 5696\n",
            "total= 5760\n",
            "total= 5824\n",
            "total= 5888\n",
            "total= 5952\n",
            "total= 6016\n",
            "total= 6080\n",
            "total= 6144\n",
            "total= 6208\n",
            "total= 6272\n",
            "total= 6336\n",
            "total= 6400\n",
            "total= 6464\n",
            "total= 6528\n",
            "total= 6592\n",
            "total= 6656\n",
            "total= 6720\n",
            "total= 6784\n",
            "total= 6848\n",
            "total= 6912\n",
            "total= 6976\n",
            "total= 7040\n",
            "total= 7104\n",
            "total= 7168\n",
            "total= 7232\n",
            "total= 7296\n",
            "total= 7360\n",
            "total= 7424\n",
            "total= 7488\n",
            "total= 7552\n",
            "total= 7616\n",
            "total= 7680\n",
            "total= 7744\n",
            "total= 7808\n",
            "total= 7872\n",
            "total= 7936\n",
            "total= 8000\n",
            "total= 8064\n",
            "total= 8128\n",
            "total= 8192\n",
            "total= 8256\n",
            "total= 8320\n",
            "total= 8384\n",
            "total= 8448\n",
            "total= 8512\n",
            "total= 8576\n",
            "total= 8640\n",
            "total= 8704\n",
            "total= 8768\n",
            "total= 8832\n",
            "total= 8896\n",
            "total= 8960\n",
            "total= 9024\n",
            "total= 9088\n",
            "total= 9152\n",
            "total= 9216\n",
            "total= 9280\n",
            "total= 9344\n",
            "total= 9408\n",
            "total= 9472\n",
            "total= 9536\n",
            "total= 9600\n",
            "total= 9664\n",
            "total= 9728\n",
            "total= 9792\n",
            "total= 9856\n",
            "total= 9920\n",
            "total= 9984\n",
            "total= 10000\n",
            "Accuracy of the network on the 10000 test images: 87.92 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images[0:100]\n",
        "        labels = labels[0:100]\n",
        "        outputs = model1(images)\n",
        "        #input(\"pls enter a code\")\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        print(\"total=\",total)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    }
  ]
}